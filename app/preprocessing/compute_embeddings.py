"""
This script computes the embeddings of the class and property descriptions previsouly generated by gen_classes_description.py.

It uses an embedding model defined in the configuration file.

The output is saved to the directory defined in param "class_embeddings_subdir" in the configuration file.
"""

from argparse import Namespace, ArgumentParser
import faiss
import os
from tqdm import tqdm
from langchain_community.vectorstores import FAISS, VectorStore
from langchain_community.docstore import InMemoryDocstore
from langchain_chroma import Chroma
import app.core.utils.config_manager as config
from app.core.utils.logger_manager import setup_logger

logger = setup_logger(__package__, __file__)


def setup_cli() -> Namespace:
    parser = ArgumentParser(
        description="Compute the embeddings of the class descriptions previsouly generated."
    )
    parser.add_argument("-p", "--params", type=str, help="Custom configuration file")
    parser.add_argument(
        "-m",
        "--model",
        type=str,
        help="Embedding model description in the configuration file. Default: 'nomic-embed-text_faiss@local'",
        default="nomic-embed-text_faiss@local",
    )
    parser.add_argument(
        "-c",
        "--classes",
        type=str,
        help='File with the description of the classes. Must be in directory "{data_directory}/{KG short name}/preprocessing". Default: "classes_with_instances_description.txt"',
        default="classes_with_instances_description.txt",
    )
    parser.add_argument(
        "--properties",
        type=str,
        help='File with the description of the properties. Must be in directory "{data_directory}/{KG short name}/preprocessing". Default: "properties_description.txt"',
        default="properties_description.txt",
    )
    return parser.parse_args()


def chunks(lst: list, n):
    """Yield successive n-sized chunks from lst."""
    for i in range(0, len(lst), n):
        yield lst[i : i + n]


def get_vector_store(embed_name: str) -> VectorStore:
    """
    Create a vector store based on the configuration of the embedding model.

    Args:
        embed_name: name of the embedding model (refers to the configuration file)

    Returns:
        VectorStore: the vector store
    """
    embed_config = config.get_embedding_model_config_by_name(embed_name)
    vector_db_name = embed_config["vector_db"]
    embedding_model = config.get_embedding_model_by_embed_name(embed_name)

    if vector_db_name == "faiss":
        vectorstore = FAISS(
            embedding_function=embedding_model,
            docstore=InMemoryDocstore(),
            index=faiss.IndexFlatL2(len(embedding_model.embed_query("hello world"))),
            index_to_docstore_id={},
        )
    elif vector_db_name == "chroma":
        embeddings_dir = f"{config.get_embeddings_directory(vector_db_name)}/{config.get_class_embeddings_subdir()}"
        vectorstore = Chroma(
            persist_directory=embeddings_dir, embedding_function=embedding_model
        )
    else:
        logger.error(f"Unsupported type of vector DB: {vector_db_name}")
        raise Exception(f"Unsupported type of vector DB: {vector_db_name}")

    return vectorstore


def compute_embeddings(embed_name: str, descriptions_file: str, output_dir: str):
    """
    Compute the embeddings of textual descriptions and save them to a file.

    Args:
        embed_name: name of the embedding model (refers to the configuration file)
        descriptions_file: file with the descriptions
    """
    # Create a vector store
    vectorstore = get_vector_store(embed_name)

    # Load the descriptions
    if not os.path.exists(descriptions_file):
        logger.error(f"Description file not found: {descriptions_file}")
        raise Exception(f"Description file not found: {descriptions_file}")
    logger.info(f"Loading descriptions from {descriptions_file}")
    f = open(descriptions_file, "r", encoding="utf8")
    descriptions = [line.strip() for line in f.readlines()]
    f.close()
    logger.info(f"Loaded {len(descriptions)} descriptions")

    # Compute the embeddings and add them the vector store
    with tqdm(total=len(descriptions), desc="Ingesting documents") as pbar:
        for sublist in chunks(descriptions, 10):
            vectorstore.add_texts(sublist)
            pbar.update(len(sublist))

    # Saving the embeddings
    logger.info(f"Saving embeddings to directory: {output_dir}")
    vectorstore.save_local(output_dir)


if __name__ == "__main__":

    # Parse the command line arguments
    args = setup_cli()

    # Load the configuration
    config.read_configuration(args)

    # The name of the embedding model refers to the configuration file
    embed_name = args.model
    embed_config = config.get_embedding_model_config_by_name(embed_name)
    vector_db_name = embed_config["vector_db"]

    # Compute the embeddings of the class descriptions
    description_file = os.path.join(
        config.get_preprocessing_directory(),
        args.classes,
    )
    embeddings_dir = f"{config.get_embeddings_directory(vector_db_name)}/{config.get_class_embeddings_subdir()}"
    compute_embeddings(embed_name, description_file, embeddings_dir)

    # Compute and save the embeddings of the property descriptions
    description_file = os.path.join(
        config.get_preprocessing_directory(),
        args.properties,
    )
    embeddings_dir = f"{config.get_embeddings_directory(vector_db_name)}/{config.get_property_embeddings_subdir()}"
    compute_embeddings(embed_name, description_file, embeddings_dir)
