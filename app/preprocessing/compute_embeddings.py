"""
This script computes the embeddings of the class and property descriptions previsouly generated by gen_classes_description.py, or
the example SPARQL queries.

It uses an embedding model defined in the configuration file.

The output is saved to the directory defined respectively in configuration params
`class_embeddings_subdir`, `property_embeddings_subdir`, or `queries_embeddings_subdir`.
"""

from argparse import Namespace, ArgumentParser
import faiss
import os
from tqdm import tqdm
from langchain_community.vectorstores import FAISS, VectorStore
from langchain_community.docstore import InMemoryDocstore
from langchain_chroma import Chroma
import app.utils.config_manager as config
from app.utils.logger_manager import setup_logger

logger = setup_logger(__package__, __file__)


def setup_cli() -> Namespace:
    parser = ArgumentParser(
        description="""Compute the embeddings of the class/property descriptions previsouly generated, or example SPARQL queries.
        The files to process must be located in a directory given by the parameters in the configuration file: {data_directory}/{KG short name}."""
    )
    parser.add_argument(
        "-p",
        "--params",
        type=str,
        help="Custom configuration file. Default: to config/params.yaml",
    )
    parser.add_argument(
        "-m",
        "--model",
        type=str,
        help="Embedding model description in the configuration file. Default: 'nomic-embed-text_faiss@local'",
        default="nomic-embed-text_faiss@local",
    )
    parser.add_argument(
        "--classes",
        type=str,
        help='File with the description of the classes. Must be located in "{data_directory}/{KG short name}/preprocessing". For example: "classes_with_instances_description.txt"',
    )
    parser.add_argument(
        "--properties",
        type=str,
        help='File with the description of the properties. Must be located in "{data_directory}/{KG short name}/preprocessing". For example: "properties_description.txt"',
    )
    parser.add_argument(
        "--sparql",
        type=str,
        help='Sub-directory containing the example SPARQL queries. Must be located in "{data_directory}/{KG short name}". For example: "example_queries"',
    )
    parser.add_argument("app.api.q2forge_api:app", nargs="?", help="Run the API")
    parser.add_argument("--reload", nargs="?", help="Debug mode")
    return parser.parse_args()


def chunks(lst: list, n):
    """Yield successive n-sized chunks from lst."""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]


def get_vector_store(embed_name: str) -> VectorStore:
    """
    Create a vector store based on the configuration of the embedding model.

    Args:
        embed_name: name of the embedding model (refers to the configuration file)

    Returns:
        VectorStore: the vector store
    """
    embed_config = config.get_embedding_model_config_by_name(embed_name)
    vector_db_name = embed_config["vector_db"]
    embedding_model = config.get_embedding_model_by_embed_name(embed_name)

    if vector_db_name == "faiss":
        db = FAISS(
            embedding_function=embedding_model,
            docstore=InMemoryDocstore(),
            index=faiss.IndexFlatL2(len(embedding_model.embed_query("hello world"))),
            index_to_docstore_id={},
        )
    elif vector_db_name == "chroma":
        embeddings_dir = f"{config.get_embeddings_directory(vector_db_name)}/{config.get_class_embeddings_subdir()}"
        db = Chroma(
            persist_directory=embeddings_dir, embedding_function=embedding_model
        )
    else:
        logger.error(f"Unsupported type of vector DB: {vector_db_name}")
        raise Exception(f"Unsupported type of vector DB: {vector_db_name}")

    return db


def compute_embeddings_from_file(embed_name: str, text_file: str, output_dir: str):
    """
    Compute the embeddings for each line of a text file, and save them to a file.

    Args:
        embed_name: name of the embedding model (refers to the configuration file)
        text_file: file where each line represents a text to compute the embedding for
    """
    # Create a vector store
    vectorstore = get_vector_store(embed_name)

    # Load the descriptions
    if not os.path.exists(text_file):
        logger.error(f"Description file not found: {text_file}")
        raise Exception(f"Description file not found: {text_file}")
    logger.info(f"Loading descriptions from {text_file}")
    f = open(text_file, "r", encoding="utf8")
    documents = [line.strip() for line in f.readlines()]
    f.close()
    logger.info(f"Loaded {len(documents)} descriptions")

    # Compute the embeddings and add them the vector store
    with tqdm(total=len(documents), desc="Ingesting documents") as pbar:
        for sublist in chunks(documents, 10):
            vectorstore.add_texts(sublist)
            pbar.update(len(sublist))

    # Saving the embeddings
    logger.info(f"Saving embeddings to directory: {output_dir}")
    vectorstore.save_local(output_dir)


def compute_embeddings_from_directory(embed_name: str, directory: str, output_dir: str):
    """
    Compute the embeddings for the text files of a directory, and save them to a file.

    Args:
        embed_name: name of the embedding model (refers to the configuration file)
        directory: where the text files are located
    """
    # Create a vector store
    vectorstore = get_vector_store(embed_name)

    # Load the descriptions
    if not os.path.exists(directory):
        logger.error(f"Directory not found: {directory}")
        raise Exception(f"Directory file not found: {directory}")
    logger.info(f"Loading files from {directory}")

    documents = []
    for filename in os.listdir(directory):
        with open(file=os.path.join(directory, filename), mode="r") as f:
            documents.append(f.read())
    logger.info(f"Loaded {len(documents)} documents")

    # Compute the embeddings and add them the vector store
    with tqdm(total=len(documents), desc="Ingesting documents") as pbar:
        for sublist in chunks(documents, 1):
            vectorstore.add_texts(sublist)
            pbar.update(len(sublist))

    # Saving the embeddings
    logger.info(f"Saving embeddings to directory: {output_dir}")
    vectorstore.save_local(output_dir)


def start_compute_embeddings(is_api_call: bool = False):
    # Parse the command line arguments
    args = setup_cli()

    # If the script is called from the API, set the parameters to default values
    if is_api_call:
        args.classes = "classes_with_instances_description.txt"
        args.properties = "properties_description.txt"
        args.sparql = "example_queries"

    # Load the configuration
    config.read_configuration(args)

    # The name of the embedding model as described in the configuration file
    embed_name = args.model
    embed_config = config.get_embedding_model_config_by_name(embed_name)
    vector_db_name = embed_config["vector_db"]

    # Compute the embeddings of the class descriptions
    if args.classes is not None:
        description_file = config.get_preprocessing_directory() / args.classes
        embeddings_dir = (
            config.get_embeddings_directory(vector_db_name)
            / config.get_class_embeddings_subdir()
        )
        compute_embeddings_from_file(embed_name, description_file, embeddings_dir)

    # Compute and save the embeddings of the property descriptions
    if args.properties is not None:
        description_file = config.get_preprocessing_directory() / args.properties
        embeddings_dir = (
            config.get_embeddings_directory(vector_db_name)
            / config.get_property_embeddings_subdir()
        )
        compute_embeddings_from_file(embed_name, description_file, embeddings_dir)

    # Compute and save the embeddings of the example SPARQL queries
    if args.sparql is not None:
        queries_dir = config.get_kg_data_directory() / args.sparql
        embeddings_dir = f"{config.get_embeddings_directory(vector_db_name)}/{config.queries_embeddings_subdir()}"
        compute_embeddings_from_directory(embed_name, queries_dir, embeddings_dir)


if __name__ == "__main__":
    start_compute_embeddings()
