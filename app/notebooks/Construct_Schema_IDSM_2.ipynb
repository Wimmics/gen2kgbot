{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the embeddings for the query examples\n",
    "\n",
    "## Prerequisits\n",
    "- [Ollama](https://ollama.com/search?c=embedding) with the embedding models: `mxbai-embed-large`, `nomic-embed-text`, `all-minilm`\n",
    "- A pkl file of the classes (check the notebook `Construct_Schema_IDSM_1.ipynb` to generate it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "logging.getLogger(\"httpx\").propagate = False\n",
    "logging.getLogger(\"httpx\").setLevel(\"CRITICAL\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the embedding variables\n",
    "\n",
    "We use the Ollama Embeddings with one of the following models `mxbai-embed-large`, `nomic-embed-text`, `all-minilm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the FAISS vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    docstore= InMemoryDocstore(),\n",
    "    index= faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\"))),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the query directory and the saving/loading path. \n",
    "\n",
    "Note that all the embeddings are available at [this MyBox URL](https://mybox.inria.fr/d/24d9423c67d64f8284fa/) you can download them to avoid waiting for the embedding process to be done. The password is: `Kc8(-8aE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the classes from the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_directory = Path(os.getcwd()).parent / 'data' / 'saved_pkls' / 'idsm'\n",
    "\n",
    "with open(f\"{classes_directory}/classes.pkl\", 'rb') as handle:\n",
    "    classes = pickle.load(handle)\n",
    "    print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = Path(os.getcwd()).parent / 'data' / 'faiss_embeddings' / 'idsm' / \"v3_4_full_nomic_faiss_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the documents to be injested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [cls.__str__() for cls in classes[:10]]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injest the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = None\n",
    "with tqdm(total=len(documents), desc=\"Ingesting documents\") as pbar:\n",
    "    for d in documents:\n",
    "        if db:\n",
    "            db.add_texts([d])\n",
    "        else:\n",
    "            db = FAISS.from_texts([d], embedding=embeddings)\n",
    "        pbar.update(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the embeddings locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the embeeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(saving_path,embeddings=embeddings,allow_dangerous_deserialization=True)\n",
    "db.index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of query selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What protein targets does donepezil (CHEBI_53289) inhibit with an IC50 less than 10 µM?\",\n",
    "    \"What protein targets does (CHEBI_124758) inhibit with an PF5 less than 10 µM?\",\n",
    "    \"protein targets donepezil (CHEBI_53289) inhibit with IC50\",\n",
    "    \"protein targets donepezil (CHEBI_53289) IC50\",\n",
    "    \"protein donepezil (CHEBI_53289) IC50\",\n",
    "    \"donepezil (CHEBI_53289) IC50\",\n",
    "    \"donepezil 53289 IC50\"\n",
    "    ]\n",
    "\n",
    "query = queries[0]\n",
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = db.similarity_search(query,k=2)\n",
    "\n",
    "# show the retrieved document's content\n",
    "for doc in retrieved_documents:\n",
    "    print(f\"{doc.page_content}\\n\\n-----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the diffrent query forms\n",
    "\n",
    "This is good to see if a preprocessing task would be benificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What protein targets does donepezil (CHEBI_53289) inhibit with an IC50 less than 10 µM?\",\n",
    "    \"protein, targets, donepezil, CHEBI_53289, inhibit, IC50\",\n",
    "    \"protein targets donepezil (CHEBI_53289) inhibit with IC50\",\n",
    "    \"protein targets donepezil (CHEBI_53289) IC50\",\n",
    "    \"protein donepezil (CHEBI_53289) IC50\",\n",
    "    \"donepezil (CHEBI_53289) IC50\",\n",
    "    \"donepezil 53289 IC50\",\n",
    "    ]\n",
    "\n",
    "to_find_iris = [\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_53289\",\n",
    "    \"http://www.bioassayontology.org/bao#BAO_0000190\",\n",
    "    \"http://www.bioassayontology.org/bao#BAO_0000040\",\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_105741\",\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_109001\",\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_109002\" ,\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_109462\" ,\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_114247\" ,\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_95316\"\n",
    "     ]\n",
    "\n",
    "\n",
    "best_q = -1\n",
    "best_score = 0\n",
    "score = 0\n",
    "\n",
    "for q in queries:\n",
    "    score = 0\n",
    "    # Retrieve the most similar text\n",
    "    retrieved_documents = db.similarity_search(q,k=20)\n",
    "\n",
    "    for doc in retrieved_documents:\n",
    "        for iri in to_find_iris:\n",
    "            if doc.page_content.find(iri) != -1:\n",
    "                score = score + 1\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_q = q\n",
    "\n",
    "    print(f\"{q} => {score}\")\n",
    "\n",
    "print()\n",
    "print(f\"{best_q} => {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the context of the selected classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from utils import construct_util\n",
    "\n",
    "\n",
    "g = construct_util.get_graph_with_prefixes()\n",
    "\n",
    "for doc in retrieved_documents:\n",
    "    cls = ast.literal_eval(doc.page_content)\n",
    "    cls_path = construct_util.format_class_graph_file(cls[0])\n",
    "    print(\"Current Classe: \"+cls[0])\n",
    "    cls_context_graph = construct_util.get_context_if_not_found(cls,cls_path)\n",
    "    g = g + cls_context_graph\n",
    "    \n",
    "saving_graph = Path(os.getcwd()).parent / 'tmp' / 'notebook_merging.ttl'\n",
    "\n",
    "# Save the graph\n",
    "g.serialize(destination=f\"{saving_graph}\", format='turtle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings with Chroma Vector Store\n",
    "\n",
    "The idea would be the same but we need to use the right classes and for saving the embeddings it is **important** to specify the `persist_directory` on the creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cn = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saving_path_chroma = Path(os.getcwd()).parent / 'data' / 'chroma_embeddings' / 'idsm' / \"v3_4_full_nomic_chroma_index\"\n",
    "dbcn = Chroma(persist_directory=str(saving_path_chroma), embedding_function=embeddings_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dbcn = None\n",
    "with tqdm(total=len(documents), desc=\"Ingesting documents\") as pbar:\n",
    "    for d in documents:\n",
    "        if dbcn:\n",
    "            dbcn.add_texts([d])\n",
    "        else:\n",
    "            dbcn = Chroma.from_texts(texts=[d], embedding=embeddings_cn,persist_directory=str(saving_path_chroma))\n",
    "        pbar.update(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the search we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcn.similarity_search(query=\"ic50\",k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgbot-rag-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
