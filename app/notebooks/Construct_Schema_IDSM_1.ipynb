{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1dcaf9",
   "metadata": {},
   "source": [
    "# KG Classes Extractor for RAG context creation\n",
    "\n",
    "This notebook would guide you through the extraction of the classes and their metadata of the [IDSM KG](https://idsm.elixir-czech.cz/chemweb) that would be used in the notebook `Similar_Query_IDSM_v1.ipynb`.\n",
    "\n",
    "IDSM is too large to query over all triples to get all unique predicates. That's why we will use the ontologies from the [void.ttl](https://ftp.ncbi.nlm.nih.gov/pubchem/RDF/void.ttl) file from PubChem RDF\n",
    "\n",
    "## Prerequisits \n",
    "- An endpoint with all the used ontologies (Note that all the ontologies are available at [this MyBox URL](https://mybox.inria.fr/d/24d9423c67d64f8284fa/) you can download them to searching / preprocessing them. The password is: `Kc8(-8aE`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a21c6",
   "metadata": {},
   "source": [
    "In the case of using Corese server, an instance can be lunched with similar command\n",
    "\n",
    "`%docker run --name my-corese -p 8080:8080 -v /path/to/IDSM/ontologies:/usr/local/corese/data  -d wimmics/corese`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceda796",
   "metadata": {},
   "source": [
    "## We import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492a6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python libs\n",
    "import os\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, TURTLE\n",
    "import glob\n",
    "import rdflib\n",
    "from rdflib import Graph\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from rdflib import RDFS, BNode, Namespace, URIRef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe85691",
   "metadata": {},
   "source": [
    "## We prepare the variables and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the remote ENPKG SPARQL endpoint\n",
    "endpoint_url_corese = 'http://localhost:8080/sparql'\n",
    "endpoint_url_idsm = 'https://idsm.elixir-czech.cz/sparql/endpoint/idsm'\n",
    "\n",
    "directory = Path(os.getcwd()).parent.parent / 'data' / 'saved_pkls' / 'idsm'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "if not os.path.exists(directory / 'schema_ttl'):\n",
    "  os.mkdir(directory / 'schema_ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56829ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cls_rel = \"\"\"\n",
    "SELECT ?property (SAMPLE(COALESCE(?type, STR(DATATYPE(?value)), \"Untyped\")) AS ?valueType) WHERE {{\n",
    "        {{\n",
    "        SELECT ?instance WHERE {{\n",
    "            ?instance a <{class_uri}> .\n",
    "        }} LIMIT 100\n",
    "        }}\n",
    "        {\n",
    "          {?instance ?property ?value .}\n",
    "        }\n",
    "        OPTIONAL {{\n",
    "        ?value a ?type .\n",
    "        }}\n",
    "    }}\n",
    "    GROUP BY ?property ?type\n",
    "    LIMIT 300\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebba271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def run_sparql(query, \n",
    "               url=endpoint_url_corese):\n",
    "    sparql = SPARQLWrapper(url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(600)\n",
    "    results = sparql.query().convert()\n",
    "    results = nested_value(results, ['results', 'bindings'])\n",
    "    return results\n",
    "\n",
    "def run_sparql_construct(query, filename, url=endpoint_url_corese):\n",
    "    sparql = SPARQLWrapper(url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(TURTLE)\n",
    "    sparql.setTimeout(600)\n",
    "    results = sparql.queryAndConvert()\n",
    "    graph = rdflib.Graph()\n",
    "    graph.parse(data=results, format='turtle')\n",
    "    graph.serialize(destination=filename, format='turtle')\n",
    "    return results\n",
    "    \n",
    "def nested_value(data: dict, path: list):\n",
    "    current = data\n",
    "    for key in path:\n",
    "        try:\n",
    "            current = current[key]\n",
    "        except:\n",
    "            return None\n",
    "    return current\n",
    "\n",
    "def get_prop_and_val_types(cls: str) -> List[Tuple[str, str]]:\n",
    "    query = query_cls_rel.replace(\"{class_uri}\",cls)\n",
    "\n",
    "    values = [(nested_value(x, ['property','value']),(nested_value(x, ['valueType','value']) )) for x in run_sparql(query,endpoint_url_idsm)]\n",
    "\n",
    "    return [] if values == [(None,None)] else values\n",
    "\n",
    "def format_class_graph_file(class_uri:str) -> str: \n",
    "    class_name = class_uri.split('/')[-1]\n",
    "    return f\"{directory}/schema_ttl/{class_name}.ttl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c8897",
   "metadata": {},
   "source": [
    "## Get all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_class = \"\"\"  \n",
    "SELECT DISTINCT ?cls ?comment ?label\n",
    "WHERE {\n",
    "?cls a owl:Class .\n",
    "OPTIONAL { ?cls rdfs:comment ?comment }\n",
    "OPTIONAL { ?cls rdfs:label ?label }\n",
    "FILTER (isIri(?cls))\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [(nested_value(x, ['cls','value']),nested_value(x, ['label','value']),nested_value(x, ['comment','value'])) for x in run_sparql(query_class,url=endpoint_url_corese)]\n",
    "classes = list(set(classes))\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ilc_tuple2str(res: Tuple[str, str, str]) -> str:\n",
    "    return f\"(<{res[0]}> , {res[1]}, {res[2]})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fea299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_str:str =(f\"In the following, each IRI is followed by the local name and optionally its description in parentheses.\\n\" \n",
    "+ f\"The RDF graph supports the following node types:\\n\"\n",
    "+ f'{\"\\n\".join([ilc_tuple2str(c) for c in classes])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078467c",
   "metadata": {},
   "source": [
    "## Save the classes in a pickle for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{directory}/classes.pkl\", 'wb') as handle:\n",
    "    pickle.dump(classes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bd9e4",
   "metadata": {},
   "source": [
    "## Load the classes from the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{directory}/classes.pkl\", 'rb') as handle:\n",
    "    classes = pickle.load(handle)\n",
    "    print(len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80debd4e",
   "metadata": {},
   "source": [
    "## Get the context of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c533a68",
   "metadata": {},
   "source": [
    "### Single thread call\n",
    "\n",
    "it would take almost 1400 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_context_class(cl:str):\n",
    "    graph = rdflib.Graph()\n",
    "    graph.bind('obo', Namespace('http://purl.obolibrary.org/obo/'),override=True)\n",
    "    graph.bind('cito', Namespace('http://purl.org/spar/cito/'),override=True)\n",
    "    graph.bind('pubchem', Namespace('http://rdf.ncbi.nlm.nih.gov/pubchem/vocabulary#'),override=True)\n",
    "    graph.bind('sio', Namespace('http://semanticscience.org/resource/'),override=True)\n",
    "    graph.bind('bao', Namespace('http://www.bioassayontology.org/bao#'),override=True)\n",
    "\n",
    "    class_ref = URIRef(cl[0])\n",
    "    properties_and_values = get_prop_and_val_types(cl[0])\n",
    "    # print(properties_and_values)\n",
    "    for property_uri, prop_type in properties_and_values:\n",
    "        value_ref = (\n",
    "            BNode() if (prop_type == \"Untyped\" or prop_type == None) else URIRef(prop_type)\n",
    "        )\n",
    "        if (cl[1]): graph.add((class_ref, RDFS.label, rdflib.term.Literal(cl[1])))\n",
    "        if(cl[2]): graph.add((class_ref, RDFS.comment, rdflib.term.Literal(cl[2])))\n",
    "        graph.add((class_ref, URIRef(property_uri), value_ref))\n",
    "    \n",
    "    # save the graph\n",
    "    class_file_path = format_class_graph_file(cl[0])\n",
    "\n",
    "    graph.serialize(destination=class_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726467e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cl in tqdm(classes, desc=\"Adding classes to graph\"):\n",
    "    get_context_class(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74ab23",
   "metadata": {},
   "source": [
    "### Multi-threading solution\n",
    "\n",
    "If we use more that 4 threads the IDSM server could crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "with tqdm(total=len(classes)) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=4) as ex:\n",
    "        futures = [ex.submit(get_context_class, url) for url in classes]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53be9e",
   "metadata": {},
   "source": [
    "### Merge les different context dans un meme fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f5224",
   "metadata": {},
   "source": [
    "Inforce the use of some prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5865d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_map = {'http://schema.org/':'schema',\n",
    "              'https://enpkg.commons-lab.org/module/':'enpkg_module',\n",
    "              'http://purl.org/pav/':'pav',\n",
    "              'http://example.org/':'example',\n",
    "              'https://enpkg.commons-lab.org/kg/':'enpkg',\n",
    "              'http://purl.obolibrary.org/obo/':'obo',\n",
    "              'http://purl.org/spar/cito/':'cito',\n",
    "              'http://rdf.ncbi.nlm.nih.gov/pubchem/vocabulary#':'pubchem',\n",
    "              'http://semanticscience.org/resource/':'sio',\n",
    "              'http://www.bioassayontology.org/bao#':'bao',\n",
    "              'http://purl.obolibrary.org/obo/CHEBI_':'chebi',\n",
    "              'http://semanticscience.org/resource/CHEMINF_':'cheminf',\n",
    "              'http://rdf.ebi.ac.uk/terms/chembl#':'chembl'\n",
    "              }\n",
    "\n",
    "# Inforce prefixes for each ttl\n",
    "for filename in glob.glob(str(directory)+'/schema_ttl/*.ttl'):\n",
    "    g = Graph()\n",
    "    g.parse(filename, format='turtle')\n",
    "\n",
    "    # Update prefix definitions\n",
    "    for namespace, prefix in prefix_map.items():\n",
    "        g.bind(prefix, namespace,override=True)\n",
    "\n",
    "    # Save the graph\n",
    "    g.serialize(destination=filename, format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8717421",
   "metadata": {},
   "source": [
    "Merge the ttl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e380b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "\n",
    "# Load all ttl files in the folder\n",
    "for filename in glob.glob(str(directory)+'/schema_ttl/*.ttl'):\n",
    "    g.parse(filename, format='turtle')\n",
    "\n",
    "# Save the merged graph\n",
    "g.serialize(destination=str(directory)+'/merged.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b51a44",
   "metadata": {},
   "source": [
    "### Counting the token size of the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the txt file\n",
    "schema_file = str(directory)+'/merged.ttl'\n",
    "with open(schema_file, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Initialize Tiktoken with the desired encoding model\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "# Count the number of tokens in the TTL file\n",
    "token_count = len(encoding.encode(content))\n",
    "\n",
    "print(f\"The Schema file '{schema_file}' contains {token_count} tokens.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen2kgbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
