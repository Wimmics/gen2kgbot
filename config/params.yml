class_context_format: turtle
class_embeddings_subdir: classes_with_instance_nomic
data_directory: ./data
excluded_classes_namespaces: []
expand_similar_classes: false
kg_description: The Wheat Genomics Scientific Literature Knowledge Graph (WheatGenomicsSLKG)
  is a FAIR knowledge graph that exploits the Semantic Web technologies to describe
  PubMed scientific articles on wheat genetics and genomics. It represents Named Entities
  (NE) about genes, phenotypes, taxa and varieties, mentioned in the title and the
  abstract of the articles, and the relationships between wheat mentions of varieties
  and phenotypes.
kg_full_name: WheatGenomic Scienctific Literature Knowledge Graph
kg_short_name: d2kab
kg_sparql_endpoint_url: http://d2kab.i3s.unice.fr/sparql
max_similar_classes: 10
ontologies_sparql_endpoint_url: http://d2kab.i3s.unice.fr/sparql
ontology_named_graphs:
- http://ns.inria.fr/d2kab/graph/wheatgenomicsslkg
- http://ns.inria.fr/d2kab/ontology/wto/v3
- http://purl.org/dc/elements/1.1/
- http://purl.org/dc/terms/
- http://purl.org/obo/owl/
- http://purl.org/ontology/bibo/
- http://purl.org/spar/fabio
- http://purl.org/vocab/frbr/core#
- http://www.w3.org/2002/07/owl#
- http://www.w3.org/2004/02/skos/core
- http://www.w3.org/ns/oa#
prefixes:
  bibo: http://purl.org/ontology/bibo/
  d2kab: http://ns.inria.fr/d2kab/
  dc: http://purl.org/dc/elements/1.1/
  dcterms: http://purl.org/dc/terms/
  fabio: http://purl.org/spar/fabio/
  foaf: http://xmlns.com/foaf/0.1/
  frbr: http://purl.org/vocab/frbr/core#
  oa: http://www.w3.org/ns/oa#
  obo: http://purl.obolibrary.org/obo/
  oio: http://www.geneontology.org/formats/oboInOwl#
  owl: http://www.w3.org/2002/07/owl#
  rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
  rdfs: http://www.w3.org/2000/01/rdf-schema#
  schema: http://schema.org/
  skos: http://www.w3.org/2004/02/skos/core#
  wto: http://opendata.inrae.fr/wto/
  xsd: http://www.w3.org/2001/XMLSchema#
properties_qnames_info: []
property_embeddings_subdir: properties_nomic
queries_embeddings_subdir: sparql_queries_nomic
scenario_1:
  ask_question: llama3_2-1b@local
  validate_question: deepseek-reasoner@hf
scenario_2:
  generate_query: llama-3_1-70B@ovh
  interpret_results: llama3_2-1b@local
  validate_question: llama3_2-1b@local
scenario_3:
  generate_query: llama-3_1-70B@ovh
  interpret_results: llama3_2-1b@local
  text_embedding_model: nomic-embed-text_faiss@local
  validate_question: llama3_2-1b@local
scenario_4:
  generate_query: llama3_2-1b@local
  interpret_results: llama3_2-1b@local
  text_embedding_model: nomic-embed-text_faiss@local
  validate_question: llama-3_1-70B@ovh
scenario_5:
  generate_query: llama3_2-1b@local
  interpret_results: llama-3_1-70B@ovh
  text_embedding_model: nomic-embed-text_faiss@local
  validate_question: llama3_2-1b@local
scenario_6:
  generate_query: deepseek-r1_1_5b@local
  interpret_results: llama3_2-1b@local
  text_embedding_model: nomic-embed-text_faiss@local
  validate_question: llama-3_1-70B@ovh
scenario_7:
  generate_query: llama-3_1-70B@ovh
  interpret_results: llama-3_1-70B@ovh
  judge_query: llama-3_1-70B@ovh
  judge_regenerate_query: llama-3_1-70B@ovh
  judging_grade_threshold_retry: 8
  judging_grade_threshold_run: 5
  text_embedding_model: nomic-embed-text_faiss@local
  validate_question: llama3_2-1b@local
seq2seq_models:
  deepseek-chat@deepseek:
    base_url: https://api.deepseek.com
    id: deepseek-chat
    max_retries: 3
    server_type: deepseek
    temperature: 0
    top_p: 0.95
  deepseek-r1-70B@ovh:
    base_url: https://deepseek-r1-distill-llama-70b.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
    id: DeepSeek-R1-Distill-Llama-70B
    max_retries: 3
    server_type: ovh
    temperature: 0
    top_p: 0.95
  deepseek-r1_1_5b@local:
    id: deepseek-r1:1.5b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  deepseek-reasoner@deepseek:
    base_url: https://api.deepseek.com
    id: deepseek-reasoner
    max_retries: 3
    server_type: deepseek
    temperature: 0
    top_p: 0.95
  deepseek-reasoner@hf:
    base_url: https://huggingface.co/api/inference-proxy/together
    id: deepseek-ai/DeepSeek-R1
    server_type: hugface
    top_p: 0.95
  gemma-3_12b@local:
    id: gemma3:12b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  gemma-3_1b@local:
    id: gemma3:1b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  gemma-3_27b@local:
    id: gemma3:27b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  gemma-3_4b@local:
    id: gemma3:4b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  gpt-4o@openai:
    id: gpt-4o
    max_retries: 3
    server_type: openai
    temperature: 0
    top_p: 0.95
  llama-3_1-70B@ovh:
    base_url: https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
    id: Meta-Llama-3_1-70B-Instruct
    max_retries: 3
    server_type: ovh
    temperature: 0
    top_p: 0.95
  llama-3_1-8B@ovh:
    base_url: https://llama-3-1-8b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/
    id: Llama-3.1-8B-Instruct
    max_retries: 3
    server_type: ovh
    temperature: 0
    top_p: 0.95
  llama-3_3-70B@ovh:
    base_url: https://llama-3-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
    id: Meta-Llama-3_3-70B-Instruct
    max_retries: 3
    server_type: ovh
    temperature: 0
    top_p: 0.95
  llama3_2-1b@local:
    id: llama3.2:1b
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  llama3_2:3b@local:
    id: llama3.2:latest
    max_retries: 3
    server_type: ollama
    temperature: 0
    top_p: 0.95
  o1@openai:
    id: o1
    server_type: openai
  o3-mini@openai:
    id: o3-mini
    server_type: openai
temp_directory: ./tmp
text_embedding_models:
  mxbai-embed-large_faiss@local:
    id: mxbai-embed-large
    server_type: ollama-embeddings
    vector_db: faiss
  nomic-embed-text_chroma@local:
    id: nomic-embed-text
    server_type: ollama-embeddings
    vector_db: chroma
  nomic-embed-text_faiss@local:
    id: nomic-embed-text
    server_type: ollama-embeddings
    vector_db: faiss
